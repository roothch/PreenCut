import os
import time
import gradio as gr
from config import (
    UPLOAD_FOLDER,
    TEMP_FOLDER,
    OUTPUT_FOLDER,
    ALLOWED_EXTENSIONS,
    MAX_FILE_SIZE,
    SPEECH_RECOGNITION_MODEL,
    WHISPERX_MODEL_SIZE
)
from modules.processing_queue import ProcessingQueue
from modules.video_processor import VideoProcessor
from typing import List, Dict, Tuple, Optional
import subprocess

# å…¨å±€å®ä¾‹
processing_queue = ProcessingQueue()


def check_uploaded_file(file) -> str:
    """æ£€æŸ¥ä¸Šä¼ çš„æ–‡ä»¶æ˜¯å¦ç¬¦åˆè¦æ±‚"""
    filename = os.path.basename(file.name)

    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    file_size = os.path.getsize(file.name)
    if file_size > MAX_FILE_SIZE:
        raise gr.Error(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ ({file_size} > {MAX_FILE_SIZE})")

    # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
    ext = os.path.splitext(filename)[1][1:].lower()
    if ext not in ALLOWED_EXTENSIONS:
        raise gr.Error(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {ext}")

    return file.name


def process_files(files: List, prompt: Optional[str] = None,
                  model_size: Optional[str] = None) -> Tuple[str, Dict]:
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
    # ä¿å­˜æ–‡ä»¶
    saved_paths = []
    for file in files:
        saved_paths.append(check_uploaded_file(file))

    # åˆ›å»ºä»»åŠ¡ID
    task_id = f"task_{int(time.time() * 1000)}"

    # æ·»åŠ åˆ°å¤„ç†é˜Ÿåˆ—
    processing_queue.add_task(task_id, saved_paths, prompt, model_size)

    return task_id, {"status": "å·²åŠ å…¥é˜Ÿåˆ—ï¼Œè¯·ç¨å€™..."}


def check_status(task_id: str) -> Dict:
    """æ£€æŸ¥ä»»åŠ¡çŠ¶æ€"""
    result = processing_queue.get_result(task_id)

    if result["status"] == "completed":
        # æ•´ç†ç»“æœä»¥ä¾¿æ˜¾ç¤º
        display_result = []
        for file_result in result["result"]:
            segments = []
            for seg in file_result["segments"]:
                segments.append([file_result["filename"],
                                 f"{seg['start']:.1f}ç§’",
                                 f"{seg['end']:.1f}ç§’",
                                 f"{seg['end'] - seg['start']:.1f}ç§’",
                                 seg["summary"],
                                 ", ".join(seg["tags"]) if isinstance(
                                     seg["tags"], list) else seg["tags"]])
                # segments.append({
                #     "æ–‡ä»¶å": file_result["filename"],
                #     "å¼€å§‹æ—¶é—´": f"{seg['start']:.1f}ç§’",
                #     "ç»“æŸæ—¶é—´": f"{seg['end']:.1f}ç§’",
                #     "æ—¶é•¿": f"{seg['end'] - seg['start']:.1f}ç§’",
                #     "å†…å®¹æ‘˜è¦": seg["summary"],
                #     "æ ‡ç­¾": ", ".join(seg["tags"]) if isinstance(seg["tags"],
                #                                                  list) else seg[
                #         "tags"]
                # })

            display_result.extend(segments)

        print(display_result)

        # return {
        #     "status": "å¤„ç†å®Œæˆ",
        #     "result": display_result,
        #     "raw_result": result["result"]
        # }
        return (
            {"status": "å¤„ç†å®Œæˆ", "raw_result": result["result"],
             "result": display_result, },
            display_result,
            display_result
        )

    elif result["status"] == "error":
        return (
            {"status": f"é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"},
            [], []
        )
        # return {"status": f"é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"}

    return (
        {"status": "å¤„ç†ä¸­..."},
        [],
        []
    )


def clip_and_download(raw_result: Dict, selected_segments: List[Dict]) -> str:
    """å‰ªè¾‘å¹¶ä¸‹è½½é€‰æ‹©çš„ç‰‡æ®µ"""
    if not raw_result or "raw_result" not in raw_result:
        raise gr.Error("æ— æ•ˆçš„å¤„ç†ç»“æœ")

    # ç»„ç»‡æ–‡ä»¶åˆ†æ®µ
    file_segments = {}
    for file_data in raw_result["raw_result"]:
        file_segments[file_data["filename"]] = file_data["segments"]

    # æ”¶é›†ç”¨æˆ·é€‰æ‹©çš„åˆ†æ®µ
    selected_clips = []
    for seg in selected_segments:
        filename = seg["æ–‡ä»¶å"]
        start = float(seg["å¼€å§‹æ—¶é—´"].replace("ç§’", ""))
        end = float(seg["ç»“æŸæ—¶é—´"].replace("ç§’", ""))

        # æ‰¾åˆ°å¯¹åº”çš„åŸå§‹åˆ†æ®µ
        for original_seg in file_segments[filename]:
            if abs(original_seg["start"] - start) < 0.5 and abs(
                    original_seg["end"] - end) < 0.5:
                selected_clips.append({
                    "filename": filename,
                    "start": original_seg["start"],
                    "end": original_seg["end"],
                    "filepath": os.path.join(UPLOAD_FOLDER, filename)
                })
                break

    # æŒ‰æ–‡ä»¶åˆ†ç»„
    clips_by_file = {}
    for clip in selected_clips:
        if clip["filename"] not in clips_by_file:
            clips_by_file[clip["filename"]] = []
        clips_by_file[clip["filename"]].append({
            "start": clip["start"],
            "end": clip["end"]
        })

    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    output_files = []
    for filename, segments in clips_by_file.items():
        input_path = os.path.join(UPLOAD_FOLDER, filename)
        output_path = os.path.join(OUTPUT_FOLDER, f"clipped_{filename}")
        VideoProcessor.clip_video(input_path, segments, output_path)
        output_files.append(output_path)

    # å¦‚æœåªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œç›´æ¥è¿”å›
    if len(output_files) == 1:
        return output_files[0]

    # åˆå¹¶å¤šä¸ªæ–‡ä»¶
    combined_path = os.path.join(OUTPUT_FOLDER, "combined_output.mp4")

    # åˆ›å»ºæ–‡ä»¶åˆ—è¡¨
    with open(os.path.join(TEMP_FOLDER, "combine_list.txt"), 'w') as f:
        for file in output_files:
            f.write(f"file '{file}'\n")

    # åˆå¹¶è§†é¢‘
    cmd = [
        'ffmpeg', '-f', 'concat', '-safe', '0',
        '-i', os.path.join(TEMP_FOLDER, "combine_list.txt"),
        '-c', 'copy', combined_path
    ]
    subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL,
                   stderr=subprocess.DEVNULL)

    return combined_path


def reanalyze_with_prompt(raw_result: Dict, new_prompt: str) -> Dict:
    """ä½¿ç”¨æ–°çš„æç¤ºé‡æ–°åˆ†æ"""
    if not raw_result or "raw_result" not in raw_result:
        raise gr.Error("æ— æ•ˆçš„å¤„ç†ç»“æœ")

    # ä½¿ç”¨æ–°æç¤ºé‡æ–°å¤„ç†
    from modules.llm_processor import LLMProcessor
    llm = LLMProcessor()
    updated_results = []

    for file_data in raw_result["raw_result"]:
        new_segments = llm.segment_video(file_data["align_result"], new_prompt)
        updated_results.append({
            "filename": file_data["filename"],
            "align_result": file_data["align_result"],
            "segments": new_segments
        })

    # æ•´ç†æ˜¾ç¤ºç»“æœ
    display_result = []
    for file_result in updated_results:
        segments = []
        for seg in file_result["segments"]:
            segments.append({
                "æ–‡ä»¶å": file_result["filename"],
                "å¼€å§‹æ—¶é—´": f"{seg['start']:.1f}ç§’",
                "ç»“æŸæ—¶é—´": f"{seg['end']:.1f}ç§’",
                "æ—¶é•¿": f"{seg['end'] - seg['start']:.1f}ç§’",
                "å†…å®¹æ‘˜è¦": seg["summary"],
                "æ ‡ç­¾": ", ".join(seg["tags"]) if isinstance(seg["tags"],
                                                             list) else seg[
                    "tags"]
            })
        display_result.extend(segments)

    return {
        "status": "é‡æ–°åˆ†æå®Œæˆ",
        "result": display_result,
        "raw_result": updated_results
    }


def create_gradio_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    with gr.Blocks(title="AIè§†é¢‘å‰ªè¾‘å·¥å…·", theme=gr.themes.Soft()) as app:
        gr.Markdown("# ğŸ¬ AIæ™ºèƒ½è§†é¢‘å‰ªè¾‘å·¥å…·")
        gr.Markdown(
            "ä¸Šä¼ è§†é¢‘/éŸ³é¢‘æ–‡ä»¶ï¼ŒAIå°†è‡ªåŠ¨è¯†åˆ«å†…å®¹ã€ç”Ÿæˆå­—å¹•ã€æ™ºèƒ½åˆ†æ®µï¼Œå¹¶å…è®¸æ‚¨é€‰æ‹©ç‰‡æ®µè¿›è¡Œå‰ªè¾‘ã€‚")

        with gr.Row():
            with gr.Column(scale=2):
                file_upload = gr.Files(
                    label="ä¸Šä¼ è§†é¢‘/éŸ³é¢‘æ–‡ä»¶",
                    file_count="multiple"
                )

                with gr.Accordion("é«˜çº§è®¾ç½®", open=False):
                    model_size = gr.Dropdown(
                        choices=["large-v2", "large-v3", "large", "medium",
                                 "small", "base", "tiny"],
                        value=WHISPERX_MODEL_SIZE,
                        label="è¯­éŸ³è¯†åˆ«æ¨¡å‹å¤§å°",
                        visible=(SPEECH_RECOGNITION_MODEL == 'whisperx')
                    )

                prompt_input = gr.Textbox(
                    label="è‡ªå®šä¹‰åˆ†ææç¤º (å¯é€‰)",
                    placeholder="ä¾‹å¦‚ï¼šæ‰¾å‡ºæ‰€æœ‰å…³äºäº§å“æ¼”ç¤ºçš„ç‰‡æ®µ",
                    lines=2
                )
                process_btn = gr.Button("å¼€å§‹å¤„ç†", variant="primary")

                with gr.Row():
                    status_display = gr.JSON(label="å¤„ç†çŠ¶æ€")
                    task_id = gr.Textbox(visible=False)

                raw_result = gr.JSON(visible=False)

            with gr.Column(scale=3):
                with gr.Tab("åˆ†æç»“æœ"):
                    result_table = gr.Dataframe(
                        headers=["æ–‡ä»¶å", "å¼€å§‹æ—¶é—´", "ç»“æŸæ—¶é—´", "æ—¶é•¿",
                                 "å†…å®¹æ‘˜è¦", "æ ‡ç­¾"],
                        datatype=["str", "str", "str", "str", "str", "str"],
                        interactive=False,
                        wrap=True
                    )

                with gr.Tab("é‡æ–°åˆ†æ"):
                    new_prompt = gr.Textbox(
                        label="è¾“å…¥æ–°çš„åˆ†ææç¤º",
                        placeholder="ä¾‹å¦‚ï¼šæ‰¾å‡ºæ‰€æœ‰åŒ…å«æŠ€æœ¯æœ¯è¯­çš„ç‰‡æ®µ",
                        lines=2
                    )
                    reanalyze_btn = gr.Button("é‡æ–°åˆ†æ", variant="secondary")

                with gr.Tab("å‰ªè¾‘é€‰é¡¹"):
                    segment_selection = gr.Dataframe(
                        headers=["æ–‡ä»¶å", "å¼€å§‹æ—¶é—´", "ç»“æŸæ—¶é—´", "æ—¶é•¿",
                                 "å†…å®¹æ‘˜è¦", "æ ‡ç­¾"],
                        datatype=["str", "str", "str", "str", "str", "str"],
                        interactive=True,
                        wrap=True,
                        type="array",
                        label="é€‰æ‹©è¦ä¿ç•™çš„ç‰‡æ®µ (æŒ‰ä½Ctrlå¯å¤šé€‰)"
                    )
                    clip_btn = gr.Button("å‰ªè¾‘å¹¶ä¸‹è½½", variant="primary")
                    download_output = gr.File(label="ä¸‹è½½å‰ªè¾‘ç»“æœ")

        # å®šæ—¶å™¨ï¼Œç”¨äºè½®è¯¢çŠ¶æ€
        timer = gr.Timer(2, active=False)
        timer.tick(check_status, task_id,
                   outputs=[status_display, result_table, segment_selection])

        # äº‹ä»¶å¤„ç†
        process_btn.click(
            process_files,
            inputs=[file_upload, prompt_input, model_size],
            outputs=[task_id, status_display]
        ).then(
            lambda: gr.Timer(active=True),
            inputs=None,
            outputs=timer,
            show_progress="hidden"
        ).then(
            lambda x: x,
            inputs=status_display,
            outputs=raw_result
        ).then(
            lambda x: x.get("result", []) if x and "result" in x else [],
            inputs=status_display,
            outputs=result_table
        ).then(
            lambda x: x.get("result", []) if x and "result" in x else [],
            inputs=status_display,
            outputs=segment_selection
        )

        reanalyze_btn.click(
            reanalyze_with_prompt,
            inputs=[raw_result, new_prompt],
            outputs=status_display
        ).then(
            lambda x: x,
            inputs=status_display,
            outputs=raw_result
        ).then(
            lambda x: x.get("result", []) if x and "result" in x else [],
            inputs=status_display,
            outputs=result_table
        ).then(
            lambda x: x.get("result", []) if x and "result" in x else [],
            inputs=status_display,
            outputs=segment_selection
        )

        clip_btn.click(
            clip_and_download,
            inputs=[raw_result, segment_selection],
            outputs=download_output
        )

        return app
