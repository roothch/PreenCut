import os
import uuid
import time
import random
import zipfile
import gradio as gr
from config import LLM_MODEL_OPTIONS

from config import (
    TEMP_FOLDER,
    OUTPUT_FOLDER,
    ALLOWED_EXTENSIONS,
    MAX_FILE_SIZE,
    SPEECH_RECOGNITION_MODEL,
    WHISPERX_MODEL_SIZE
)
from modules.processing_queue import ProcessingQueue
from modules.video_processor import VideoProcessor
from utils import seconds_to_hhmmss, hhmmss_to_seconds, clear_directory_fast \
    , generate_safe_filename
from typing import List, Dict, Tuple, Optional
import subprocess

# å…¨å±€å®ä¾‹
processing_queue = ProcessingQueue()
CHECKBOX_CHECKED = '<span style="display: flex; width: 16px; height: 16px; border: 2px solid blue; background:#4B6BFB ;font-weight: bold;color:white;align-items:center;justify-content:center">âœ“</span>'
CHECKBOX_UNCHECKED = '<span style="display: flex; width: 16px; height: 16px; border: 2px solid blue;font-weight: bold;color:white;align-items:center;justify-content:center"></span>'


def check_uploaded_file(file) -> str:
    """æ£€æŸ¥ä¸Šä¼ çš„æ–‡ä»¶æ˜¯å¦ç¬¦åˆè¦æ±‚"""
    filename = os.path.basename(file.name)

    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    file_size = os.path.getsize(file.name)
    if file_size > MAX_FILE_SIZE:
        raise gr.Error(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ ({file_size} > {MAX_FILE_SIZE})")

    # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
    ext = os.path.splitext(filename)[1][1:].lower()
    if ext not in ALLOWED_EXTENSIONS:
        raise gr.Error(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {ext}")

    return file.name


def process_files(files: List, llm_model: str,
                  prompt: Optional[str] = None,
                  whisper_model_size: Optional[str] = None) -> Tuple[
    str, Dict]:
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""

    print('å½“å‰results', processing_queue.results, flush=True)

    # ä¿å­˜æ–‡ä»¶
    saved_paths = []
    for file in files:
        saved_paths.append(check_uploaded_file(file))

    # åˆ›å»ºå”¯ä¸€ä»»åŠ¡ID
    task_id = f"task_{uuid.uuid4().hex}"

    # æ·»åŠ åˆ°å¤„ç†é˜Ÿåˆ—
    processing_queue.add_task(task_id, saved_paths, llm_model, prompt,
                              whisper_model_size)

    return task_id, {"status": "å·²åŠ å…¥é˜Ÿåˆ—ï¼Œè¯·ç¨å€™..."}


def check_status(task_id: str) -> Tuple[Dict, List, List, gr.Timer]:
    """æ£€æŸ¥ä»»åŠ¡çŠ¶æ€"""
    result = processing_queue.get_result(task_id)

    if result["status"] == "completed":
        # æ•´ç†ç»“æœä»¥ä¾¿æ˜¾ç¤º
        display_result = []
        clip_result = []
        for file_result in result["result"]:
            for seg in file_result["segments"]:
                row = [file_result["filename"],
                       f"{seconds_to_hhmmss(seg['start'])}",
                       f"{seconds_to_hhmmss(seg['end'])}",
                       f"{seconds_to_hhmmss(seg['end'] - seg['start'])}",
                       seg["summary"],
                       ", ".join(seg["tags"]) if isinstance(
                           seg["tags"], list) else seg["tags"]]
                clip_row = row.copy()
                clip_row.insert(0, CHECKBOX_UNCHECKED)  # æ·»åŠ é€‰æ‹©æ¡†
                display_result.append(row)
                clip_result.append(clip_row)

        return (
            {"task_id": task_id, "status": "å¤„ç†å®Œæˆ",
             "raw_result": result["result"],
             "result": display_result, },
            display_result,
            clip_result,
            gr.Timer(active=False)
        )

    elif result["status"] == "error":
        return (
            {"task_id": task_id,
             "status": f"é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"},
            [], [], gr.update()
        )
    elif result["status"] == "queued":
        return (
            {"task_id": task_id,
             "status": f"æ’é˜Ÿä¸­, å‰é¢è¿˜æœ‰{processing_queue.get_queue_size() + 1}ä¸ªä»»åŠ¡"},
            [], [], gr.update()
        )

    if task_id:
        return (
            {"task_id": task_id, "status": "å¤„ç†ä¸­...",
             "status_info": result.get("status_info", "")},
            [], [], gr.update()
        )
    else:
        return (
            {"task_id": "", "status": ""},
            [], [], gr.update()
        )


def select_clip(segment_selection: List[List], evt: gr.SelectData) -> List[
    List]:
    """é€‰æ‹©å‰ªè¾‘ç‰‡æ®µ"""
    selected_row = segment_selection[evt.index[0]]
    # åˆ‡æ¢é€‰æ‹©çŠ¶æ€
    selected_row[0] = CHECKBOX_CHECKED \
        if selected_row[0] == CHECKBOX_UNCHECKED else CHECKBOX_UNCHECKED
    return segment_selection


def clip_and_download(status_display: Dict,
                      segment_selection: List[List], download_mode: str) -> str:
    """å‰ªè¾‘å¹¶ä¸‹è½½é€‰æ‹©çš„ç‰‡æ®µ"""
    if not status_display or "raw_result" not in status_display:
        raise gr.Error("æ— æ•ˆçš„å¤„ç†ç»“æœ")

    # è·å–ä»»åŠ¡IDç”¨äºåˆ›å»ºå”¯ä¸€ç›®å½•
    task_id = status_display.get("task_id",
                                 f"temp_{int(time.time() * 1000)}_{random.randint(1000, 9999)}")
    task_temp_dir = os.path.join(TEMP_FOLDER, task_id)
    task_output_dir = os.path.join(OUTPUT_FOLDER, task_id)

    if os.path.exists(task_output_dir):
        clear_directory_fast(task_output_dir)
    else:
        os.makedirs(task_output_dir, exist_ok=True)
    if os.path.exists(task_temp_dir):
        clear_directory_fast(task_temp_dir)
    else:
        os.makedirs(task_temp_dir, exist_ok=True)

    # ç»„ç»‡æ–‡ä»¶åˆ†æ®µ
    file_segments = {}
    for file_data in status_display["raw_result"]:
        file_segments[file_data["filename"]] = {
            "segments": file_data["segments"],
            "filepath": file_data["filepath"],
            "ext": os.path.splitext(file_data["filepath"])[1]  # è·å–åŸå§‹æ–‡ä»¶æ‰©å±•å
        }

    selected_segments = [seg for seg in segment_selection if
                         seg[0] == CHECKBOX_CHECKED]

    # å¤„ç†"åˆå¹¶æˆä¸€ä¸ªæ–‡ä»¶"çš„æƒ…å†µ
    if download_mode == "åˆå¹¶æˆä¸€ä¸ªæ–‡ä»¶":
        # æ£€æŸ¥æ‰€æœ‰ç‰‡æ®µæ ¼å¼æ˜¯å¦ä¸€è‡´
        formats = set()
        for seg in selected_segments:
            filename = seg[1]
            file_ext = file_segments[filename]['ext']
            formats.add(file_ext.lower())

        if len(formats) > 1:
            raise gr.Error(
                "æ— æ³•åˆå¹¶: æ‰€é€‰ç‰‡æ®µåŒ…å«å¤šç§æ ¼å¼: " + ", ".join(formats))

    selected_clips = []
    for seg in selected_segments:
        filename = seg[1]
        start = hhmmss_to_seconds(seg[2])
        end = hhmmss_to_seconds(seg[3])

        # æ‰¾åˆ°å¯¹åº”çš„åŸå§‹åˆ†æ®µ
        for original_seg in file_segments[filename]['segments']:
            if abs(original_seg["start"] - start) < 0.5 and abs(
                    original_seg["end"] - end) < 0.5:
                selected_clips.append({
                    "filename": filename,
                    "start": original_seg["start"],
                    "end": original_seg["end"],
                    "filepath": file_segments[filename]['filepath'],
                    "ext": file_segments[filename]['ext']  # æ·»åŠ æ‰©å±•å
                })
                break

    # æŒ‰æ–‡ä»¶åˆ†ç»„
    clips_by_file = {}
    for clip in selected_clips:
        if clip["filename"] not in clips_by_file:
            clips_by_file[clip["filename"]] = {
                "filepath": clip["filepath"],
                "ext": clip["ext"],
                "segments": []
            }
        clips_by_file[clip["filename"]]['segments'].append({
            "start": clip["start"],
            "end": clip["end"],
        })

    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    output_files = []
    for filename, segments in clips_by_file.items():
        input_path = segments['filepath']
        # ç”Ÿæˆå®‰å…¨çš„ç›®å½•å(ä¸€ä¸ªæ–‡ä»¶å¯èƒ½æœ‰å¤šä¸ªç‰‡æ®µï¼Œæ”¾åœ¨ä»¥è¿™ä¸ªæ–‡ä»¶åä¸ºåçš„ç›®å½•ä¸‹)
        safe_filename = generate_safe_filename(filename)
        output_folder = os.path.join(task_output_dir, safe_filename)
        os.makedirs(output_folder, exist_ok=True)
        single_file_clips = VideoProcessor.clip_video(input_path,
                                                      segments['segments'],
                                                      output_folder,
                                                      segments['ext'])
        output_files.extend(single_file_clips)

    # å¦‚æœåªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œç›´æ¥è¿”å›
    if len(output_files) == 1:
        return output_files[0]

    # æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„æ¨¡å¼å¤„ç†
    if download_mode == "åˆå¹¶æˆä¸€ä¸ªæ–‡ä»¶":
        # åˆå¹¶å¤šä¸ªæ–‡ä»¶
        ext = clips_by_file[next(iter(clips_by_file))]['ext']  # è·å–ç¬¬ä¸€ä¸ªæ–‡ä»¶çš„æ‰©å±•å
        combined_path = os.path.join(task_output_dir, f"combined_output{ext}")

        # åˆ›å»ºæ–‡ä»¶åˆ—è¡¨
        with open(os.path.join(task_temp_dir, "combine_list.txt"), 'w') as f:
            for file in output_files:
                f.write(f"file '../../{file}'\n")

        # åˆå¹¶è§†é¢‘
        cmd = [
            'ffmpeg', '-f', 'concat', '-safe', '0',
            '-i', os.path.join(task_temp_dir, "combine_list.txt"),
            '-c', 'copy', combined_path
        ]
        try:
            subprocess.run(cmd, check=True, capture_output=True)
        except subprocess.CalledProcessError as e:
            print(f"FFmpeg error: {e.stderr.decode('utf-8')}")
            raise gr.Error(f"æ–‡ä»¶åˆå¹¶å¤±è´¥: {str(e)}")

        return combined_path

    # æ‰“åŒ…æˆzipæ–‡ä»¶
    else:
        # åˆ›å»ºzipæ–‡ä»¶
        zip_path = os.path.join(task_output_dir, "clipped_segments.zip")
        with zipfile.ZipFile(zip_path, 'w') as zipf:
            for file_path in output_files:
                # åœ¨zipæ–‡ä»¶ä¸­ä½¿ç”¨ç›¸å¯¹è·¯å¾„
                arcname = os.path.basename(file_path)
                zipf.write(file_path, arcname)

        return zip_path


def start_reanalyze() -> Dict:
    return {
        'status': 'è¯·ç¨å€™ï¼Œæ­£åœ¨ä½¿ç”¨æ–°çš„æç¤ºé‡æ–°åˆ†æ...',
    }


def reanalyze_with_prompt(task_id: str, reanalyze_llm_model: str,
                          new_prompt: str) -> Tuple[
    Dict, List[List], List[List]]:
    """ä½¿ç”¨æ–°çš„æç¤ºé‡æ–°åˆ†æ"""
    if not task_id:
        raise gr.Error("æ— æ•ˆçš„ä»»åŠ¡ID")
    task_result = processing_queue.get_result(task_id)
    if not task_result or "result" not in task_result:
        raise gr.Error("æ²¡æœ‰å¯ä»¥é‡æ–°åˆ†æçš„å†…å®¹")

    if not new_prompt:
        raise gr.Error("è¯·è¾“å…¥æ–°çš„åˆ†ææç¤º")

    if not reanalyze_llm_model:
        raise gr.Error("è¯·é€‰æ‹©å¤§è¯­è¨€æ¨¡å‹")

    try:
        # ä½¿ç”¨æ–°æç¤ºé‡æ–°å¤„ç†
        from modules.llm_processor import LLMProcessor
        llm = LLMProcessor(reanalyze_llm_model)
        updated_results = []

        for file_data in task_result["result"]:
            new_segments = llm.segment_video(file_data["align_result"],
                                             new_prompt)
            updated_results.append({
                "filename": file_data["filename"],
                "filepath": file_data["filepath"],
                "align_result": file_data["align_result"],
                "segments": new_segments
            })

        # æ•´ç†ç»“æœä»¥ä¾¿æ˜¾ç¤º
        display_result = []
        clip_result = []
        for file_result in updated_results:
            for seg in file_result["segments"]:
                row = [file_result["filename"],
                       f"{seconds_to_hhmmss(seg['start'])}",
                       f"{seconds_to_hhmmss(seg['end'])}",
                       f"{seconds_to_hhmmss(seg['end'] - seg['start'])}",
                       seg["summary"],
                       ", ".join(seg["tags"]) if isinstance(
                           seg["tags"], list) else seg["tags"]]
                clip_row = row.copy()
                clip_row.insert(0, CHECKBOX_UNCHECKED)  # æ·»åŠ é€‰æ‹©æ¡†
                display_result.append(row)
                clip_result.append(clip_row)

        return ({
                    "task_id": task_id,
                    "status": "é‡æ–°åˆ†æå®Œæˆï¼Œè¯·åœ¨åˆ†æç»“æœä¸­æŸ¥çœ‹",
                    "result": display_result,
                    "raw_result": updated_results
                }, display_result, clip_result)

    except Exception as e:
        print(f"é‡æ–°åˆ†æå¤±è´¥: {str(e)}")
        task_result["status"] = "error"
        task_result["status_info"] = f"é‡æ–°åˆ†æå¤±è´¥: {str(e)}"
        return task_result, [], []


def create_gradio_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    with (gr.Blocks(title="PreenCut", theme=gr.themes.Soft()) as app):
        gr.Markdown("# ğŸ¬ PreenCut-AIè§†é¢‘å‰ªè¾‘åŠ©æ‰‹")
        gr.Markdown(
            "ä¸Šä¼ åŒ…å«è¯­éŸ³çš„è§†é¢‘/éŸ³é¢‘æ–‡ä»¶ï¼ŒAIå°†è‡ªåŠ¨è¯†åˆ«è¯­éŸ³å†…å®¹ã€æ™ºèƒ½åˆ†æ®µï¼Œå¹¶å…è®¸æ‚¨è¾“å…¥è‡ªç„¶è¯­è¨€è¿›è¡Œæ£€ç´¢ã€‚")

        with gr.Row():
            with gr.Column(scale=2):
                file_upload = gr.Files(
                    label="ä¸Šä¼ è§†é¢‘/éŸ³é¢‘æ–‡ä»¶",
                    file_count="multiple"
                )

                with gr.Accordion("é«˜çº§è®¾ç½®", open=False):
                    llm_model = gr.Dropdown(
                        choices=[model['label'] for model in LLM_MODEL_OPTIONS],
                        value="è±†åŒ…", label="å¤§è¯­è¨€æ¨¡å‹")
                    model_size = gr.Dropdown(
                        choices=["large-v2", "large-v3", "large", "medium",
                                 "small", "base", "tiny"],
                        value=WHISPERX_MODEL_SIZE,
                        label="è¯­éŸ³è¯†åˆ«æ¨¡å‹å¤§å°",
                        visible=(SPEECH_RECOGNITION_MODEL == 'whisperx')
                    )

                prompt_input = gr.Textbox(
                    label="è‡ªå®šä¹‰åˆ†ææç¤º (å¯é€‰)",
                    placeholder="ä¾‹å¦‚ï¼šæ‰¾å‡ºæ‰€æœ‰å…³äºäº§å“æ¼”ç¤ºçš„ç‰‡æ®µ",
                    lines=2
                )
                process_btn = gr.Button("å¼€å§‹å¤„ç†", variant="primary")

                with gr.Row():
                    status_display = gr.JSON(label="å¤„ç†çŠ¶æ€")
                    task_id = gr.Textbox(visible=False)

            with gr.Column(scale=3):
                with gr.Tab("åˆ†æç»“æœ"):
                    result_table = gr.Dataframe(
                        headers=["æ–‡ä»¶å", "å¼€å§‹æ—¶é—´", "ç»“æŸæ—¶é—´", "æ—¶é•¿",
                                 "å†…å®¹æ‘˜è¦", "æ ‡ç­¾"],
                        datatype=["str", "str", "str", "str", "str", "str"],
                        interactive=False,
                        wrap=True
                    )

                with gr.Tab("é‡æ–°åˆ†æ"):
                    new_prompt = gr.Textbox(
                        label="è¾“å…¥æ–°çš„åˆ†ææç¤º",
                        placeholder="ä¾‹å¦‚ï¼šæ‰¾å‡ºæ‰€æœ‰åŒ…å«æŠ€æœ¯æœ¯è¯­çš„ç‰‡æ®µ",
                        lines=2
                    )
                    reanalyze_llm_model = gr.Dropdown(
                        choices=[model['label'] for model in LLM_MODEL_OPTIONS],
                        value="è±†åŒ…", label="å¤§è¯­è¨€æ¨¡å‹")
                    reanalyze_btn = gr.Button("é‡æ–°åˆ†æ", variant="secondary")

                with gr.Tab("å‰ªè¾‘é€‰é¡¹"):
                    segment_selection = gr.Dataframe(
                        headers=["é€‰æ‹©", "æ–‡ä»¶å", "å¼€å§‹æ—¶é—´", "ç»“æŸæ—¶é—´",
                                 "æ—¶é•¿",
                                 "å†…å®¹æ‘˜è¦", "æ ‡ç­¾"],
                        datatype='html',
                        interactive=False,
                        wrap=True,
                        type="array",
                        label="é€‰æ‹©è¦ä¿ç•™çš„ç‰‡æ®µ"
                    )
                    segment_selection.select(select_clip,
                                             inputs=segment_selection,
                                             outputs=segment_selection)
                    # æ·»åŠ ä¸‹è½½æ¨¡å¼é€‰æ‹©
                    download_mode = gr.Radio(
                        choices=["æ‰“åŒ…æˆzipæ–‡ä»¶", "åˆå¹¶æˆä¸€ä¸ªæ–‡ä»¶"],
                        label="é€‰æ‹©å¤šä¸ªæ–‡ä»¶æ—¶çš„å¤„ç†æ–¹å¼",
                        value="æ‰“åŒ…æˆzipæ–‡ä»¶"
                    )
                    clip_btn = gr.Button("å‰ªè¾‘", variant="primary")
                    download_output = gr.File(label="ä¸‹è½½å‰ªè¾‘ç»“æœ")

        # å®šæ—¶å™¨ï¼Œç”¨äºè½®è¯¢çŠ¶æ€
        timer = gr.Timer(2, active=False)
        timer.tick(check_status, task_id,
                   outputs=[status_display, result_table, segment_selection,
                            timer])

        # äº‹ä»¶å¤„ç†
        process_btn.click(
            process_files,
            inputs=[file_upload, llm_model, prompt_input, model_size],
            outputs=[task_id, status_display]
        ).then(
            lambda: gr.Timer(active=True),
            inputs=None,
            outputs=timer,
            show_progress="hidden"
        )

        reanalyze_btn.click(
            start_reanalyze,
            inputs=None,
            outputs=status_display,
        ).then(
            reanalyze_with_prompt,
            inputs=[task_id, reanalyze_llm_model, new_prompt],
            outputs=[status_display, result_table, segment_selection],
            show_progress="hidden"
        )

        clip_btn.click(
            clip_and_download,
            inputs=[status_display, segment_selection, download_mode],
            outputs=download_output
        )

        return app
